{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98998a55-1347-49b4-bc8e-fb9424274edd",
   "metadata": {},
   "source": [
    "# Project (final assessment of STK 353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import Datasets\n",
    "from Datasets import Source_Code\n",
    "import re\n",
    "\n",
    "# get data from source code\n",
    "Honda_accord_2008_data = Source_Code.send_honda_accord_2008_data()\n",
    "Honda_accord_2009_data = Source_Code.send_honda_accord_2009_data()\n",
    "Hyundai_sonata_2009_data = Source_Code.send_hyundai_sonata_2008_data()\n",
    "Toyota_corolla_2009_data = Source_Code.send_toyota_corolla_2009_data() \n",
    "\n",
    "type(Honda_accord_2008_data)\n",
    "#Toyota_corolla_2009_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# parse the data files as html to datasets.\n",
    "with open(\"Datasets/2008_honda_accord\", \"r\") as file:\n",
    "    honda_accord_2008_file = file.read()\n",
    "\n",
    "Honda_accord_2008_soup = BeautifulSoup(honda_accord_2008_file, 'html.parser')\n",
    "#exclusion criteria in reading the file\n",
    "def is_excluded(tag):\n",
    "    return tag.name != 'docno'\n",
    "\n",
    "unique_tags = set(tag.name for tag in Honda_accord_2008_soup.find_all(is_excluded))\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stan branch just pushed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b2b84-8ff6-4989-9c27-a0c7c10a37d0",
   "metadata": {},
   "source": [
    "Let's discuss the car datasets `2009_honda_accord`, `2009_hyundai_sonata`, and `2009_toyota_corolla`. These datasets contain customer reviews for three different car models from 2009. \n",
    "\n",
    "1. As a stakeholder representing these companies, your objective is to determine which car has acheived the highest customer satisfaction rate among the three.\n",
    "\n",
    "2. Additionally, you want to investigate whether the satisfaction rate for the Honda Accord has improved from 2008 to 2009. To answer this question, you will also need to analyze the dataset `2008_honda_accord`, which consists of customer reviews for the Honda Accord from the year 2008.\n",
    "\n",
    "3. In the end, your final goal is to categorize the customer reviews for the Honda Accord (only those of the year 2008) into $k$ meaningful groups.\n",
    "\n",
    "To answer the above questions, please consider the following points:\n",
    "- a) Obtain the number of comments given in all four reviews and report the results.\n",
    "- b) In the cleaning process, using lemmatization rather than stemming is recommended (Why?)\n",
    "- c) During the cleaning process, you also need to remove numbers and HTML tags e.g. `<DOC>, <TEXT>, <AUTHOR>` and similar elements.\n",
    "- d)  The first two questions can be solved using sentiment analysis techniques.\n",
    "- e) Create appropriate `wordcloud`s for each part to visualize the most frequent words in the reviews.\n",
    "- f) Determine the optimal value of $k$ from the set $\\{2, 3, 4, 5\\}$ in Question 3.\n",
    "- g) (_optional_) Feel free to obtain any other relevant outputs, such as evaluation metrics or additional plots.\n",
    "- h) (_optional_) If you find that the algorithm used in Question 3 does not provide satisfactory performance, you can try incorporating the datasets `2008_honda_accord` and `2009_honda_accord` to cluster the reviews again, aiming for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbb24fe-2a0c-4313-8366-7516f7976d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 224 262 226\n"
     ]
    }
   ],
   "source": [
    "# a) Obtain the number of comments given in all four reviews and report the results.\n",
    "\n",
    "#pattern to use for the regex code.\n",
    "pattern = r\"<DOC>.*?</DOC>\"\n",
    "\n",
    "\n",
    "# Count the number of occurrences using a regex to count the number of comments\n",
    "accord_08_comment_count = len(Honda_accord_2008_data['doc'].isna())\n",
    "accord_09_comment_count =  len(Honda_accord_2009_data['doc'].isna())\n",
    "sonata_09_comment_count =  len(Hyundai_sonata_2009_data['doc'].isna())\n",
    "corolla_09_comment_count =  len(Toyota_corolla_2009_data['doc'].isna())\n",
    "\n",
    "#print results\n",
    "print(accord_08_comment_count, accord_09_comment_count, sonata_09_comment_count, corolla_09_comment_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- b) In the cleaning process, using lemmatization rather than stemming is recommended (Why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- c) During the cleaning process, you also need to remove numbers and HTML tags e.g. `<DOC>, <TEXT>, <AUTHOR>` and similar elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- d)  The first two questions can be solved using sentiment analysis techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- e) Create appropriate `wordcloud`s for each part to visualize the most frequent words in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- f) Determine the optimal value of k from the set {2, 3, 4, 5\\} in Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- g) (_optional_) Feel free to obtain any other relevant outputs, such as evaluation metrics or additional plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- h) (_optional_) If you find that the algorithm used in Question 3 does not provide satisfactory performance, you can try incorporating the datasets `2008_honda_accord` and `2009_honda_accord` to cluster the reviews again, aiming for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
